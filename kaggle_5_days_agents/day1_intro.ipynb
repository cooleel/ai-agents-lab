{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53dcb98",
   "metadata": {},
   "source": [
    "## Example code from kaggle 5days ai agents course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e58c2",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a457ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-adk\n",
      "  Downloading google_adk-1.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=6.0.2 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (6.0.3)\n",
      "Collecting aiosqlite>=0.21.0 (from google-adk)\n",
      "  Downloading aiosqlite-0.22.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.9.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (4.12.0)\n",
      "Collecting authlib<2.0.0,>=1.5.1 (from google-adk)\n",
      "  Downloading authlib-1.6.6-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.8 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (8.3.1)\n",
      "Collecting fastapi<0.124.0,>=0.115.0 (from google-adk)\n",
      "  Downloading fastapi-0.123.10-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (2.187.0)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.125.0 (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n",
      "  Downloading google_cloud_aiplatform-1.132.0-py2.py3-none-any.whl.metadata (46 kB)\n",
      "Collecting google-cloud-bigquery-storage>=2.0.0 (from google-adk)\n",
      "  Downloading google_cloud_bigquery_storage-2.36.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-bigquery>=2.2.0 (from google-adk)\n",
      "  Downloading google_cloud_bigquery-3.39.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting google-cloud-bigtable>=2.32.0 (from google-adk)\n",
      "  Downloading google_cloud_bigtable-2.35.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting google-cloud-discoveryengine<0.14.0,>=0.13.12 (from google-adk)\n",
      "  Downloading google_cloud_discoveryengine-0.13.12-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting google-cloud-secret-manager<3.0.0,>=2.22.0 (from google-adk)\n",
      "  Downloading google_cloud_secret_manager-2.26.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting google-cloud-spanner<4.0.0,>=3.56.0 (from google-adk)\n",
      "  Downloading google_cloud_spanner-3.61.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting google-cloud-speech<3.0.0,>=2.30.0 (from google-adk)\n",
      "  Downloading google_cloud_speech-2.35.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting google-cloud-storage<4.0.0,>=2.18.0 (from google-adk)\n",
      "  Downloading google_cloud_storage-3.7.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting google-genai<2.0.0,>=1.55.0 (from google-adk)\n",
      "  Downloading google_genai-1.56.0-py3-none-any.whl.metadata (53 kB)\n",
      "Collecting graphviz<1.0.0,>=0.20.2 (from google-adk)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (4.25.1)\n",
      "Collecting mcp<2.0.0,>=1.10.0 (from google-adk)\n",
      "  Downloading mcp-1.25.0-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting opentelemetry-api<=1.37.0,>=1.37.0 (from google-adk)\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-gcp-logging<2.0.0,>=1.9.0a0 (from google-adk)\n",
      "  Downloading opentelemetry_exporter_gcp_logging-1.11.0a0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 (from google-adk)\n",
      "  Downloading opentelemetry_exporter_gcp_monitoring-1.11.0a0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting opentelemetry-exporter-gcp-trace<2.0.0,>=1.9.0 (from google-adk)\n",
      "  Downloading opentelemetry_exporter_gcp_trace-1.11.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.36.0 (from google-adk)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 (from google-adk)\n",
      "  Downloading opentelemetry_resourcedetector_gcp-1.11.0a0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting opentelemetry-sdk<=1.37.0,>=1.37.0 (from google-adk)\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pyarrow>=14.0.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (22.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (2.10.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (1.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (2.32.4)\n",
      "Collecting sqlalchemy-spanner>=1.14.0 (from google-adk)\n",
      "  Downloading sqlalchemy_spanner-1.17.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sqlalchemy<3.0.0,>=2.0 (from google-adk)\n",
      "  Downloading sqlalchemy-2.0.45-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting starlette<1.0.0,>=0.49.1 (from google-adk)\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tenacity<10.0.0,>=9.0.0 (from google-adk)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-adk) (4.15.0)\n",
      "Collecting tzlocal<6.0,>=5.3 (from google-adk)\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting uvicorn<1.0.0,>=0.34.0 (from google-adk)\n",
      "  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting watchdog<7.0.0,>=6.0.0 (from google-adk)\n",
      "  Downloading watchdog-6.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (44 kB)\n",
      "Collecting websockets<16.0.0,>=15.0.1 (from google-adk)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.11)\n",
      "Requirement already satisfied: cryptography in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from authlib<2.0.0,>=1.5.1->google-adk) (45.0.7)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<0.124.0,>=0.115.0->google-adk)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.31.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.40.3)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.2.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.28.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3.0.0,>=2.157.0->google-adk) (1.72.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3.0.0,>=2.157.0->google-adk) (6.33.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3.0.0,>=2.157.0->google-adk) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.9.1)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 (from google-api-python-client<3.0.0,>=2.157.0->google-adk)\n",
      "  Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (25.0)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n",
      "  Downloading google_cloud_resource_manager-1.15.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.1.1)\n",
      "Requirement already satisfied: docstring_parser<1 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.17.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.71.2)\n",
      "Requirement already satisfied: cloudpickle<4.0,>=3.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.1.1)\n",
      "Collecting google-cloud-trace<2 (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n",
      "  Downloading google_cloud_trace-1.17.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting google-cloud-logging<4 (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n",
      "  Downloading google_cloud_logging-3.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0 (from google-adk)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery>=2.2.0->google-adk)\n",
      "  Using cached google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery>=2.2.0->google-adk)\n",
      "  Downloading google_resumable_media-2.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-cloud-appengine-logging<2.0.0,>=0.1.3 (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n",
      "  Downloading google_cloud_appengine_logging-1.7.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-audit-log<1.0.0,>=0.3.1 (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n",
      "  Downloading google_cloud_audit_log-0.4.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.12.4 (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n",
      "  Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting sqlparse>=0.4.4 (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk)\n",
      "  Downloading sqlparse-0.5.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk)\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions>=0.43b0 (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting google-cloud-monitoring>=2.16.0 (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk)\n",
      "  Downloading google_cloud_monitoring-2.28.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mmh3>=4.1.0 (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage<4.0.0,>=2.18.0->google-adk)\n",
      "  Downloading google_crc32c-1.8.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.55.0->google-adk) (0.28.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.55.0->google-adk) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.55.0->google-adk) (1.3.1)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3.0.0,>=2.157.0->google-adk)\n",
      "  Using cached protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.2.5)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.55.0->google-adk) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.55.0->google-adk) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.55.0->google-adk) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (0.28.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from mcp<2.0.0,>=1.10.0->google-adk) (0.4.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from mcp<2.0.0,>=1.10.0->google-adk) (2.11.0)\n",
      "Collecting pyjwt>=2.10.1 (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.10.0->google-adk)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.10.0->google-adk)\n",
      "  Downloading python_multipart-0.0.21-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.10.0->google-adk)\n",
      "  Downloading sse_starlette-3.0.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.1 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from mcp<2.0.0,>=1.10.0->google-adk) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (3.23.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk)\n",
      "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-http to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.36.0 (from google-adk)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.39.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.0 (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.0 (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk)\n",
      "  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.36.0 (from google-adk)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.36.0 (from google-adk)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions>=0.43b0 (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk)\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.0->google-adk)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.1 (from mcp<2.0.0,>=1.10.0->google-adk)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.4->google-adk) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.4->google-adk) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.2.6)\n",
      "Requirement already satisfied: cffi>=1.14 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from cffi>=1.14->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.23)\n",
      "Collecting alembic (from sqlalchemy-spanner>=1.14.0->google-adk)\n",
      "  Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting Mako (from alembic->sqlalchemy-spanner>=1.14.0->google-adk)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/miniconda3/envs/tensorlake/lib/python3.12/site-packages (from Mako->alembic->sqlalchemy-spanner>=1.14.0->google-adk) (3.0.2)\n",
      "Downloading google_adk-1.21.0-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading authlib-1.6.6-py2.py3-none-any.whl (244 kB)\n",
      "Downloading fastapi-0.123.10-py3-none-any.whl (111 kB)\n",
      "Downloading google_cloud_aiplatform-1.132.0-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
      "Downloading google_cloud_bigquery-3.39.0-py3-none-any.whl (259 kB)\n",
      "Using cached google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_discoveryengine-0.13.12-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_logging-3.13.0-py3-none-any.whl (230 kB)\n",
      "Downloading google_cloud_appengine_logging-1.7.0-py3-none-any.whl (16 kB)\n",
      "Downloading google_cloud_audit_log-0.4.0-py3-none-any.whl (44 kB)\n",
      "Downloading google_cloud_resource_manager-1.15.0-py3-none-any.whl (397 kB)\n",
      "Downloading google_cloud_secret_manager-2.26.0-py3-none-any.whl (223 kB)\n",
      "Downloading google_cloud_spanner-3.61.0-py3-none-any.whl (515 kB)\n",
      "Downloading google_cloud_speech-2.35.0-py3-none-any.whl (342 kB)\n",
      "Downloading google_cloud_storage-3.7.0-py3-none-any.whl (303 kB)\n",
      "Downloading google_cloud_trace-1.17.0-py3-none-any.whl (104 kB)\n",
      "Downloading google_crc32c-1.8.0-cp312-cp312-macosx_12_0_arm64.whl (31 kB)\n",
      "Downloading google_genai-1.56.0-py3-none-any.whl (426 kB)\n",
      "Downloading google_resumable_media-2.8.0-py3-none-any.whl (81 kB)\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Downloading grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
      "Downloading mcp-1.25.0-py3-none-any.whl (233 kB)\n",
      "Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_gcp_logging-1.11.0a0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_exporter_gcp_monitoring-1.11.0a0-py3-none-any.whl (13 kB)\n",
      "Downloading google_cloud_monitoring-2.28.0-py3-none-any.whl (384 kB)\n",
      "Downloading opentelemetry_exporter_gcp_trace-1.11.0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_resourcedetector_gcp-1.11.0a0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Using cached protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.45-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Downloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "Downloading watchdog-6.0.0-cp312-cp312-macosx_11_0_arm64.whl (89 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading aiosqlite-0.22.1-py3-none-any.whl (17 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading google_cloud_bigquery_storage-2.36.0-py3-none-any.whl (303 kB)\n",
      "Downloading google_cloud_bigtable-2.35.0-py3-none-any.whl (540 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.3/540.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Downloading mmh3-5.2.0-cp312-cp312-macosx_11_0_arm64.whl (40 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading python_multipart-0.0.21-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy_spanner-1.17.2-py3-none-any.whl (31 kB)\n",
      "Downloading sqlparse-0.5.5-py3-none-any.whl (46 kB)\n",
      "Downloading sse_starlette-3.0.4-py3-none-any.whl (11 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: websockets, watchdog, uvicorn, tzlocal, typing-inspection, tenacity, sqlparse, sqlalchemy, python-multipart, pyjwt, pydantic-core, protobuf, mmh3, Mako, graphviz, google-crc32c, annotated-doc, aiosqlite, starlette, pydantic, opentelemetry-proto, opentelemetry-api, grpc-interceptor, google-resumable-media, google-auth, alembic, sse-starlette, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, google-cloud-audit-log, fastapi, authlib, opentelemetry-sdk, mcp, grpc-google-iam-v1, google-genai, google-cloud-core, opentelemetry-resourcedetector-gcp, opentelemetry-exporter-otlp-proto-http, google-cloud-trace, google-cloud-storage, google-cloud-speech, google-cloud-secret-manager, google-cloud-resource-manager, google-cloud-monitoring, google-cloud-discoveryengine, google-cloud-bigtable, google-cloud-bigquery-storage, google-cloud-bigquery, google-cloud-appengine-logging, opentelemetry-exporter-gcp-trace, opentelemetry-exporter-gcp-monitoring, google-cloud-spanner, google-cloud-logging, google-cloud-aiplatform, sqlalchemy-spanner, opentelemetry-exporter-gcp-logging, google-adk\n",
      "\u001b[2K  Attempting uninstall: websockets\n",
      "\u001b[2K    Found existing installation: websockets 14.2\n",
      "\u001b[2K    Uninstalling websockets-14.2:\n",
      "\u001b[2K      Successfully uninstalled websockets-14.2\n",
      "\u001b[2K  Attempting uninstall: typing-inspection\n",
      "\u001b[2K    Found existing installation: typing-inspection 0.4.1\n",
      "\u001b[2K    Uninstalling typing-inspection-0.4.1:\n",
      "\u001b[2K      Successfully uninstalled typing-inspection-0.4.1\n",
      "\u001b[2K  Attempting uninstall: tenacity\n",
      "\u001b[2K    Found existing installation: tenacity 8.5.0\n",
      "\u001b[2K    Uninstalling tenacity-8.5.0:\n",
      "\u001b[2K      Successfully uninstalled tenacity-8.5.0\n",
      "\u001b[2K  Attempting uninstall: pydantic-core━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/58\u001b[0m [sqlalchemy]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.27.2━━━━━━━━━\u001b[0m \u001b[32m 7/58\u001b[0m [sqlalchemy]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.27.2:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/58\u001b[0m [sqlalchemy]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.27.2━━━━━━━━━━━\u001b[0m \u001b[32m 7/58\u001b[0m [sqlalchemy]\n",
      "\u001b[2K  Attempting uninstall: protobufm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/58\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/58\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Uninstalling protobuf-6.33.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/58\u001b[0m [pydantic-core]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/58\u001b[0m [pydantic-core]\n",
      "\u001b[2K  Attempting uninstall: pydantic━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/58\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Found existing installation: pydantic 2.10.4━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/58\u001b[0m [pydantic]]\n",
      "\u001b[2K    Uninstalling pydantic-2.10.4:90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/58\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.10.4━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/58\u001b[0m [pydantic]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-proto━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/58\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: opentelemetry-proto 1.33.1━━━\u001b[0m \u001b[32m19/58\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling opentelemetry-proto-1.33.1:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/58\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-proto-1.33.1━━━━━\u001b[0m \u001b[32m19/58\u001b[0m [pydantic]\n",
      "\u001b[2K  Attempting uninstall: google-authm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/58\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Found existing installation: google-auth 2.40.3━━━━━━━━━━━\u001b[0m \u001b[32m21/58\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Uninstalling google-auth-2.40.3:m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/58\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K      Successfully uninstalled google-auth-2.40.3━━━━━━━━━━━━━\u001b[0m \u001b[32m21/58\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K  Attempting uninstall: google-genai0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/58\u001b[0m [authlib]y-api]\n",
      "\u001b[2K    Found existing installation: google-genai 1.51.0━━━━━━━━━━\u001b[0m \u001b[32m31/58\u001b[0m [authlib]\n",
      "\u001b[2K    Uninstalling google-genai-1.51.0:0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/58\u001b[0m [authlib]\n",
      "\u001b[2K      Successfully uninstalled google-genai-1.51.0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35/58\u001b[0m [google-genai]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58/58\u001b[0m [google-adk]ogle-adk]ogle-cloud-aiplatform]rage]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-tools 1.76.0 requires protobuf<7.0.0,>=6.31.1, but you have protobuf 5.29.5 which is incompatible.\n",
      "paddlex 3.3.8 requires PyYAML==6.0.2, but you have pyyaml 6.0.3 which is incompatible.\n",
      "docling 2.21.0 requires typer<0.13.0,>=0.12.5, but you have typer 0.20.0 which is incompatible.\n",
      "docling-core 2.50.0 requires typer<0.20.0,>=0.12.5, but you have typer 0.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.10 aiosqlite-0.22.1 alembic-1.17.2 annotated-doc-0.0.4 authlib-1.6.6 fastapi-0.123.10 google-adk-1.21.0 google-auth-2.45.0 google-cloud-aiplatform-1.132.0 google-cloud-appengine-logging-1.7.0 google-cloud-audit-log-0.4.0 google-cloud-bigquery-3.39.0 google-cloud-bigquery-storage-2.36.0 google-cloud-bigtable-2.35.0 google-cloud-core-2.5.0 google-cloud-discoveryengine-0.13.12 google-cloud-logging-3.13.0 google-cloud-monitoring-2.28.0 google-cloud-resource-manager-1.15.0 google-cloud-secret-manager-2.26.0 google-cloud-spanner-3.61.0 google-cloud-speech-2.35.0 google-cloud-storage-3.7.0 google-cloud-trace-1.17.0 google-crc32c-1.8.0 google-genai-1.56.0 google-resumable-media-2.8.0 graphviz-0.21 grpc-google-iam-v1-0.14.3 grpc-interceptor-0.15.4 mcp-1.25.0 mmh3-5.2.0 opentelemetry-api-1.37.0 opentelemetry-exporter-gcp-logging-1.11.0a0 opentelemetry-exporter-gcp-monitoring-1.11.0a0 opentelemetry-exporter-gcp-trace-1.11.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-resourcedetector-gcp-1.11.0a0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 protobuf-5.29.5 pydantic-2.12.5 pydantic-core-2.41.5 pyjwt-2.10.1 python-multipart-0.0.21 sqlalchemy-2.0.45 sqlalchemy-spanner-1.17.2 sqlparse-0.5.5 sse-starlette-3.0.4 starlette-0.50.0 tenacity-9.1.2 typing-inspection-0.4.2 tzlocal-5.3.1 uvicorn-0.40.0 watchdog-6.0.0 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-adk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini_key = \"xxx\"\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf7972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import google_search\n",
    "from google.genai import types\n",
    "\n",
    "print(\"✅ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2ae319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reties\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,  # Initial delay before first retry (in seconds)\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "\n",
    "# 429 is rate limit error\n",
    "# 500 is internal server error\n",
    "# 503 is service unavailable\n",
    "# 504 is gateway timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0faf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Root Agent defined.\n"
     ]
    }
   ],
   "source": [
    "### First agent\n",
    "#### a simple agent use google search\n",
    "root_agent = Agent(\n",
    "    name=\"helpful_assistant\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    description=\"A simple agent that can answer general questions.\",\n",
    "    instruction=\"You are a helpful assistant. Use Google Search for current info or if unsure.\",\n",
    "    tools=[google_search],\n",
    ")\n",
    "\n",
    "print(\"✅ Root Agent defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08072d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Runner created.\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "\n",
    "print(\"✅ Runner created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98e4ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Continue session: debug_session_id\n",
      "\n",
      "User > What is the temperature of Hawaii today?\n",
      "helpful_assistant > The temperature in Hawaii today, December 25, 2025, is around 68°F (20°C) in Hawaii County. In Honolulu, the high is expected to be around 82°F (28°C) with a RealFeel® of 82°F, and the low is around 70°F (21°C) with a RealFeel® of 68°F. Other reports for Honolulu indicate a high near 79°F to 82°F and a low near 71°F to 73°F.\n"
     ]
    }
   ],
   "source": [
    "response = await runner.run_debug(\n",
    "    \"What is the temperature of Hawaii today?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04284b6",
   "metadata": {},
   "source": [
    "### Multi-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8126ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types\n",
    "\n",
    "print(\"✅ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c31206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ research_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Research Agent: Its job is to use the google_search tool and present findings.\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n",
    "    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n",
    ")\n",
    "\n",
    "print(\"✅ research_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6077b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ summarizer_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Summarizer Agent: Its job is to summarize the text it receives.\n",
    "summarizer_agent = Agent(\n",
    "    name=\"SummarizerAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    # The instruction is modified to request a bulleted list for a clear output format.\n",
    "    instruction=\"\"\"Read the provided research findings: {research_findings}\n",
    "Create a concise summary as a bulleted list with 3-5 key points.\"\"\",\n",
    "    output_key=\"final_summary\",\n",
    ")\n",
    "\n",
    "print(\"✅ summarizer_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f8b138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ root_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\n",
    "root_agent = Agent(\n",
    "    name=\"ResearchCoordinator\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n",
    "    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n",
    "1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n",
    "2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n",
    "3. Finally, present the final summary clearly to the user as your response.\"\"\",\n",
    "    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n",
    "    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n",
    ")\n",
    "\n",
    "print(\"✅ root_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c08ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > What are the latest advancements in open source multimodality lanugage models used in ai agents?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResearchCoordinator > The latest advancements in open-source multimodal language models for AI agents are characterized by enhanced capabilities in understanding and processing diverse data types, a robust and growing open-source ecosystem, sophisticated agentic features, significant performance improvements, and a wide range of real-world applications.\n",
      "\n",
      "Key developments include:\n",
      "*   **Enhanced Multimodal Understanding:** Models can now simultaneously process and reason across text, images, audio, and video, leading to more comprehensive comprehension and improved performance. Examples include Grok-1.5V and Qwen3-VL.\n",
      "*   **Thriving Open-Source Ecosystem:** The availability of open-source models like Aria, LLaVA, GLM-4.6V, and Llama 3.2-Vision is democratizing AI development by providing transparency, customization options, and the ability for self-hosting.\n",
      "*   **Advanced Agentic Capabilities:** AI agents are gaining the ability to use multimodal tools directly (e.g., GLM-4.6V) and engage in collaborative task execution with other specialized agents.\n",
      "*   **Significant Performance Gains and Efficiency:** These models are achieving notable accuracy improvements, and there is a strong focus on developing more efficient and faster processing solutions, such as MiniCPM-Llama3-V 2.6.\n",
      "*   **Broad Real-World Impact:** The advancements are driving practical applications across various sectors, including healthcare diagnostics, autonomous systems, and workflow automation, largely fueled by collaborative efforts within the open-source community.\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"What are the latest advancements in open source multimodality lanugage models used in ai agents?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17794713",
   "metadata": {},
   "source": [
    "\n",
    "### Example: Blog Post Creation with Sequential Agents\n",
    "#### Instead of just specific instructions, we can also use a structured approach to guide the agent's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6fd4623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ outline_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Outline Agent: Creates the initial blog post outline.\n",
    "outline_agent = Agent(\n",
    "    name=\"OutlineAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Create a blog outline for the given topic with:\n",
    "    1. A catchy headline\n",
    "    2. An introduction hook\n",
    "    3. 3-5 main sections with 2-3 bullet points for each\n",
    "    4. A concluding thought\"\"\",\n",
    "    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n",
    ")\n",
    "\n",
    "print(\"✅ outline_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b345df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ writer_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Writer Agent: Writes the full blog post based on the outline from the previous agent.\n",
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n",
    "    instruction=\"\"\"Following this outline strictly: {blog_outline}\n",
    "    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n",
    "    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n",
    ")\n",
    "\n",
    "print(\"✅ writer_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9650aa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ editor_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Editor Agent: Edits and polishes the draft from the writer agent.\n",
    "editor_agent = Agent(\n",
    "    name=\"EditorAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    # This agent receives the `{blog_draft}` from the writer agent's output.\n",
    "    instruction=\"\"\"Edit this draft: {blog_draft}\n",
    "    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n",
    "    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n",
    ")\n",
    "\n",
    "print(\"✅ editor_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d8c10e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sequential Agent created.\n"
     ]
    }
   ],
   "source": [
    "root_agent = SequentialAgent(\n",
    "    name=\"BlogPipeline\",\n",
    "    sub_agents=[outline_agent, writer_agent, editor_agent],\n",
    ")\n",
    "\n",
    "print(\"✅ Sequential Agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76a2b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Write a blog post about how to use open source vision lanugage models for ai agents\n",
      "OutlineAgent > ## Outline:\n",
      "\n",
      "**Headline:** Unleash Your AI Agent's Superpowers: Harnessing Open-Source Vision-Language Models\n",
      "\n",
      "**Introduction Hook:** Imagine an AI agent that can not only understand complex instructions but also \"see\" and interpret its environment. This isn't science fiction anymore! Open-source Vision-Language Models (VLMs) are revolutionizing how we build intelligent agents, empowering them with a nuanced understanding of both the visual and textual worlds. Ready to unlock this next level of AI capability?\n",
      "\n",
      "**Main Section 1: What are Vision-Language Models (VLMs) and Why They Matter for Agents**\n",
      "\n",
      "*   **Bridging the Gap:** Explain how VLMs combine the power of computer vision (understanding images) and natural language processing (understanding text) to create a unified understanding.\n",
      "*   **Enhanced Agent Capabilities:** Discuss how this integration allows agents to perform tasks that require visual context, such as following visual instructions, describing scenes, answering questions about images, or even generating text based on visual input.\n",
      "*   **The Open-Source Advantage:** Highlight the benefits of using open-source VLMs, including cost-effectiveness, community support, transparency, and the ability to fine-tune models for specific agent needs.\n",
      "\n",
      "**Main Section 2: Key Open-Source VLMs for Your Agent Toolkit**\n",
      "\n",
      "*   **Introducing the Players:** Briefly introduce 2-3 prominent open-source VLMs (e.g., CLIP, BLIP, LLaVA). Mention their core strengths and what makes them suitable for agent development.\n",
      "*   **Choosing the Right Model:** Provide guidance on factors to consider when selecting a VLM for an agent project, such as model size, computational requirements, performance on specific tasks, and licensing.\n",
      "*   **Getting Started with Implementation:** Offer a brief overview of how developers can integrate these models into their agent frameworks, mentioning popular libraries or APIs.\n",
      "\n",
      "**Main Section 3: Practical Applications and Use Cases for Agents with VLMs**\n",
      "\n",
      "*   **Visual Navigation and Interaction:** Discuss how agents can use VLMs to navigate physical or virtual environments, identify objects, and interact with them based on visual cues and textual commands.\n",
      "*   **Contextual Reasoning and Decision Making:** Explain how VLMs enable agents to reason about complex situations by understanding the interplay between visual information and natural language instructions, leading to more intelligent decisions.\n",
      "*   **Assisted Creativity and Content Generation:** Explore how agents powered by VLMs can assist in tasks like generating image captions, writing descriptions for visual products, or even creating storyboards from textual prompts.\n",
      "\n",
      "**Main Section 4: Challenges and Future Directions**\n",
      "\n",
      "*   **Overcoming Limitations:** Briefly touch upon current challenges, such as computational costs, the need for large datasets, and potential biases within the models.\n",
      "*   **The Evolving Landscape:** Discuss emerging trends and research in VLMs, such as multi-modal reasoning, real-time processing, and improved robustness for agent applications.\n",
      "*   **Ethical Considerations:** Briefly touch upon the importance of responsible development and deployment of VLM-powered agents.\n",
      "\n",
      "**Conclusion:** The fusion of vision and language through open-source VLMs is a game-changer for AI agents. By understanding and interpreting the world visually, these agents can move beyond simple command execution to truly intelligent, contextualized action. As the open-source community continues to innovate, the potential for sophisticated, capable AI agents is limitless. Are you ready to build the next generation of intelligent agents?\n",
      "WriterAgent > ## Unleash Your AI Agent's Superpowers: Harnessing Open-Source Vision-Language Models\n",
      "\n",
      "Imagine an AI agent that doesn't just follow commands but can also *see* and understand its surroundings. This is no longer the realm of science fiction! Open-source Vision-Language Models (VLMs) are transforming AI agents, equipping them with a powerful understanding of both visual and textual information. Ready to elevate your agent's capabilities?\n",
      "\n",
      "VLMs bridge the gap between computer vision and natural language processing, creating a unified understanding that's crucial for intelligent agents. This integration allows agents to perform complex tasks like following visual instructions, describing scenes, answering questions about images, and even generating text based on visual input. The beauty of open-source VLMs? They offer cost-effectiveness, robust community support, transparency, and the flexibility to fine-tune them for your specific agent needs.\n",
      "\n",
      "Leading the charge are models like CLIP, BLIP, and LLaVA, each offering unique strengths for agent development. When choosing, consider factors like model size, computational demands, performance on specific tasks, and licensing. Integrating these models into your agent framework is becoming increasingly accessible with popular libraries and APIs.\n",
      "\n",
      "The applications are vast: imagine agents navigating environments using visual cues, making context-aware decisions, or even assisting in creative tasks by generating image captions or descriptions. While challenges like computational costs and potential biases exist, the rapid evolution of VLMs promises even more sophisticated, robust, and ethically developed agents.\n",
      "\n",
      "The fusion of vision and language through open-source VLMs is undeniably a game-changer. Are you ready to build the next generation of intelligent agents?\n",
      "EditorAgent > ## Unleash Your AI Agent's Superpowers: Harnessing Open-Source Vision-Language Models\n",
      "\n",
      "Imagine an AI agent that doesn't just follow commands but can also *see* and understand its surroundings. This is no longer the realm of science fiction! Open-source Vision-Language Models (VLMs) are revolutionizing AI agents, equipping them with a powerful understanding of both visual and textual information. Are you ready to elevate your agent's capabilities?\n",
      "\n",
      "VLMs bridge the gap between computer vision and natural language processing, creating a unified understanding that's crucial for intelligent agents. This integration allows agents to perform complex tasks such as following visual instructions, describing scenes, answering questions about images, and even generating text based on visual input. The beauty of open-source VLMs lies in their cost-effectiveness, robust community support, transparency, and the flexibility to fine-tune them for your specific agent needs.\n",
      "\n",
      "Leading the charge are models like CLIP, BLIP, and LLaVA, each offering unique strengths for agent development. When choosing a VLM, consider factors such as model size, computational demands, performance on specific tasks, and licensing. Integrating these models into your agent framework is becoming increasingly accessible with popular libraries and APIs.\n",
      "\n",
      "The applications are vast. Imagine agents navigating environments using visual cues, making context-aware decisions, or even assisting in creative tasks by generating image captions or descriptions. While challenges like computational costs and potential biases exist, the rapid evolution of VLMs promises even more sophisticated, robust, and ethically developed agents.\n",
      "\n",
      "The fusion of vision and language through open-source VLMs is undeniably a game-changer. Are you ready to build the next generation of intelligent agents?\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"Write a blog post about how to use open source vision lanugage models for ai agents\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c645e",
   "metadata": {},
   "source": [
    "### Example: Parallel Multi-Topic Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d21340ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ tech_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Tech Researcher: Focuses on AI and ML trends.\n",
    "tech_researcher = Agent(\n",
    "    name=\"TechResearcher\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\n",
    "the main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n",
    ")\n",
    "\n",
    "print(\"✅ tech_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c426a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ health_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Health Researcher: Focuses on medical breakthroughs.\n",
    "health_researcher = Agent(\n",
    "    name=\"HealthResearcher\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\n",
    "their practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"health_research\",  # The result will be stored with this key.\n",
    ")\n",
    "\n",
    "print(\"✅ health_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "538340b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ finance_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Finance Researcher: Focuses on fintech trends.\n",
    "finance_researcher = Agent(\n",
    "    name=\"FinanceResearcher\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\n",
    "their market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"finance_research\",  # The result will be stored with this key.\n",
    ")\n",
    "\n",
    "print(\"✅ finance_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbf3bab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ aggregator_agent created.\n"
     ]
    }
   ],
   "source": [
    "# The AggregatorAgent runs *after* the parallel step to synthesize the results.\n",
    "aggregator_agent = Agent(\n",
    "    name=\"AggregatorAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n",
    "    instruction=\"\"\"Combine these three research findings into a single executive summary:\n",
    "\n",
    "    **Technology Trends:**\n",
    "    {tech_research}\n",
    "    \n",
    "    **Health Breakthroughs:**\n",
    "    {health_research}\n",
    "    \n",
    "    **Finance Innovations:**\n",
    "    {finance_research}\n",
    "    \n",
    "    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n",
    "    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n",
    ")\n",
    "\n",
    "print(\"✅ aggregator_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c8a6e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parallel and Sequential Agents created.\n"
     ]
    }
   ],
   "source": [
    "# The ParallelAgent runs all its sub-agents simultaneously.\n",
    "parallel_research_team = ParallelAgent(\n",
    "    name=\"ParallelResearchTeam\",\n",
    "    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n",
    ")\n",
    "\n",
    "# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"ResearchSystem\",\n",
    "    sub_agents=[parallel_research_team, aggregator_agent],\n",
    ")\n",
    "\n",
    "print(\"✅ Parallel and Sequential Agents created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b2e0989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Run the daily AI news on multimodality models and agents on Tech, Health, and Finance\n",
      "FinanceResearcher > **Key Fintech Trends in AI: Multimodality, Agents, and Enhanced Reasoning**\n",
      "\n",
      "**1. Multimodal AI Models:** These models process diverse data types (text, image, audio, video) simultaneously, leading to more comprehensive insights. Market implications include advanced fraud detection, personalized customer experiences, and richer risk analysis. The future outlook points to more sophisticated models that can understand context and nuance, driving innovation in areas like sentiment analysis and market prediction.\n",
      "\n",
      "**2. Agentic AI Systems:** AI agents are autonomous programs capable of planning and executing tasks. In finance, this translates to automated trading, proactive customer service, and streamlined compliance. The market is seeing rapid adoption, with implications for efficiency gains and new service models. The future anticipates agents deeply integrated into workflows, acting as digital colleagues.\n",
      "\n",
      "**3. Enhanced Reasoning and Prediction:** AI models are moving beyond descriptive analysis to predictive capabilities. This is crucial for forecasting market trends, optimizing portfolios, and managing risk. The market impact is a shift towards more proactive and data-driven decision-making. The outlook is for AI to become a compounding asset, enabling forward-looking applications across logistics, healthcare, and security.\n",
      "TechResearcher > Here are three key AI/ML trends:\n",
      "\n",
      "1.  **Multimodal Models:** AI systems that can process and generate information across various data types (text, images, audio, video).\n",
      "    *   **Companies Involved:** Google (Gemini models), OpenAI (Sora), Meta (Llama models), Microsoft (Azure AI).\n",
      "    *   **Potential Impact:** More human-like AI interactions, advanced content creation (e.g., video generation), enhanced diagnostics in healthcare by combining image and text data, and more intuitive virtual assistants.\n",
      "\n",
      "2.  **AI Agents:** Autonomous or semi-autonomous AI systems designed to perform complex tasks with minimal human intervention.\n",
      "    *   **Companies Involved:** Microsoft, Google, and various startups developing agentic AI frameworks.\n",
      "    *   **Potential Impact:** Automation of complex workflows, improved efficiency in business operations, enhanced customer service through proactive task management, and new possibilities in software development and research.\n",
      "\n",
      "3.  **Generative AI Advancement:** Continued rapid evolution of generative AI, leading to more sophisticated content generation, increased efficiency, and broader accessibility.\n",
      "    *   **Companies Involved:** OpenAI, Google, Meta, and numerous open-source communities.\n",
      "    *   **Potential Impact:** Significant economic impact across industries, revolutionizing content creation, accelerating drug discovery and diagnostics in healthcare, enhancing financial fraud detection with synthetic data, and democratizing AI development through open-source platforms.\n",
      "HealthResearcher > Here are three significant recent medical breakthroughs driven by AI:\n",
      "\n",
      "1.  **Multimodal AI for Enhanced Diagnostics:** AI models are now integrating diverse data types like medical images (X-rays, MRIs), clinical notes, and genetic information to achieve more accurate diagnoses. This approach is expected to improve early disease detection and personalized treatment plans. Practical applications are emerging, with full integration into clinical settings anticipated within 1-2 years.\n",
      "\n",
      "2.  **AI Agents as Medical Assistants:** Intelligent AI agents are automating routine tasks, improving patient safety, and streamlining workflows. They can assist with diagnostics, manage appointments, and provide patient support, freeing up medical professionals. Widespread adoption in administrative and routine tasks is expected within the next 1-3 years.\n",
      "\n",
      "3.  **Accelerated Drug Discovery with Agentic AI:** AI agents are significantly speeding up the drug discovery and development process. By simulating compound reactions and testing hypotheses autonomously, they reduce the time and cost associated with bringing new therapies to market. This acceleration could lead to new treatments becoming available in 3-5 years.\n",
      "AggregatorAgent > **Executive Summary: AI's Transformative Impact Across Industries**\n",
      "\n",
      "The convergence of multimodal AI, AI agents, and advanced generative capabilities is rapidly reshaping technology, healthcare, and finance. A key common thread is the ability of **multimodal AI** to process and synthesize diverse data types – from images and text to audio and video – leading to richer insights and more human-like interactions. In healthcare, this translates to significantly enhanced diagnostics by combining medical images with clinical notes and genetic data. In finance, it drives more sophisticated fraud detection and nuanced market analysis.\n",
      "\n",
      "Simultaneously, the rise of **AI agents** signifies a shift towards autonomous task execution. These intelligent agents are automating complex workflows across industries, from business operations and software development in tech to streamlining administrative tasks and providing patient support in healthcare. In finance, agents are enabling automated trading and proactive customer service.\n",
      "\n",
      "The impact is profound: these AI advancements are accelerating innovation, increasing efficiency, and democratizing access to powerful tools. Healthcare is poised for faster drug discovery and more accurate diagnoses, while finance is moving towards proactive, data-driven decision-making. The overarching takeaway is AI's accelerating role as a catalyst for transformative change, with significant real-world applications emerging within the next few years.\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"Run the daily AI news on multimodality models and agents on Tech, Health, and Finance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197ee84",
   "metadata": {},
   "source": [
    "### Example: Iterative Story Refinement (loop agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a3fd791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ initial_writer_agent created.\n"
     ]
    }
   ],
   "source": [
    "# This agent runs ONCE at the beginning to create the first draft.\n",
    "initial_writer_agent = Agent(\n",
    "    name=\"InitialWriterAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n",
    "    Output only the story text, with no introduction or explanation.\"\"\",\n",
    "    output_key=\"current_story\",  # Stores the first draft in the state.\n",
    ")\n",
    "\n",
    "print(\"✅ initial_writer_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3e2c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ critic_agent created.\n"
     ]
    }
   ],
   "source": [
    "# This agent's only job is to provide feedback or the approval signal. It has no tools.\n",
    "critic_agent = Agent(\n",
    "    name=\"CriticAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n",
    "    Story: {current_story}\n",
    "    \n",
    "    Evaluate the story's plot, characters, and pacing.\n",
    "    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n",
    "    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n",
    "    output_key=\"critique\",  # Stores the feedback in the state.\n",
    ")\n",
    "\n",
    "print(\"✅ critic_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24abcdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ exit_loop function created.\n"
     ]
    }
   ],
   "source": [
    "# This is the function that the RefinerAgent will call to exit the loop.\n",
    "def exit_loop():\n",
    "    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n",
    "    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n",
    "\n",
    "\n",
    "print(\"✅ exit_loop function created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98e504ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ refiner_agent created.\n"
     ]
    }
   ],
   "source": [
    "# This agent refines the story based on critique OR calls the exit_loop function.\n",
    "refiner_agent = Agent(\n",
    "    name=\"RefinerAgent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n",
    "    \n",
    "    Story Draft: {current_story}\n",
    "    Critique: {critique}\n",
    "    \n",
    "    Your task is to analyze the critique.\n",
    "    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n",
    "    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n",
    "    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n",
    "    tools=[\n",
    "        FunctionTool(exit_loop)\n",
    "    ],  # The tool is now correctly initialized with the function reference.\n",
    ")\n",
    "\n",
    "print(\"✅ refiner_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c730720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loop and Sequential Agents created.\n"
     ]
    }
   ],
   "source": [
    "# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\n",
    "story_refinement_loop = LoopAgent(\n",
    "    name=\"StoryRefinementLoop\",\n",
    "    sub_agents=[critic_agent, refiner_agent],\n",
    "    max_iterations=2,  # Prevents infinite loops\n",
    ")\n",
    "\n",
    "# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"StoryPipeline\",\n",
    "    sub_agents=[initial_writer_agent, story_refinement_loop],\n",
    ")\n",
    "\n",
    "print(\"✅ Loop and Sequential Agents created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7a8261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Write a short story about a little girl who sees stars and blue skys at the same time\n",
      "InitialWriterAgent > Lily pressed her nose against the cool glass of the observatory window. Outside, the sky was a brilliant, cloudless blue, the kind that promised a perfect summer day. Yet, through the massive telescope, a different world unfolded. Pinpricks of light, impossibly distant and ancient, glittered against a velvet darkness.\n",
      "\n",
      "\"How can it be both, Mama?\" she whispered, her breath fogging the pane.\n",
      "\n",
      "Her mother smiled, tracing the constellations Lily pointed out. \"Because, my sweet star-gazer, the sky is very big. The sun lights up our little piece, but beyond it, the stars have always been there, waiting to be seen.\" Lily nodded, a universe of wonder opening before her very eyes.\n",
      "CriticAgent > The story is a charming vignette with a clear premise and a touching moment between mother and daughter. However, to enhance its impact and completeness, here are a few suggestions:\n",
      "\n",
      "1.  **Expand on Lily's wonder and the \"how\":** While Lily's question is posed, the explanation, though poetic, is quite abstract. Consider showing Lily's *process* of trying to reconcile the two views. Perhaps she looks from the telescope to the window and back again, her brow furrowed, before her mother's words click. This would make her eventual understanding feel more earned.\n",
      "\n",
      "2.  **Add sensory details beyond sight:** The story is very visual. What does the observatory *smell* like (dusty books, polished brass)? What does the telescope *feel* like (cold, smooth)? What does Lily *hear* besides her own whisper (the hum of equipment, the distant sounds of the summer day)? These details can further immerse the reader in the scene.\n",
      "\n",
      "3.  **Give the mother a brief moment of observation:** While the focus is rightly on Lily, a quick sentence about her observing Lily's reaction, or a fleeting thought she has about Lily's curiosity, could add another layer to her character and the scene. For example, \"Her mother watched Lily's face, alight with a wonder she herself had felt as a child, and felt a familiar warmth spread through her.\"\n",
      "RefinerAgent > Lily pressed her nose against the cool glass of the observatory window, the faint scent of old paper and polished brass tickling her nostrils. Outside, the sky was a brilliant, cloudless blue, the kind that promised a perfect, buzzing summer day. She could almost hear the distant drone of lawnmowers and children's laughter. Yet, through the massive, cold cylinder of the telescope, a different world unfolded. Pinpricks of light, impossibly distant and ancient, glittered against a velvet darkness that seemed to swallow all sound.\n",
      "\n",
      "She looked from the blinding blue outside to the speckled void in the eyepiece, her brow furrowed in a knot of confusion. \"How can it be both, Mama?\" she whispered, her breath fogging the pane. She pulled back, then leaned in again, her small hand resting on the telescope's smooth, metallic curve. It felt solid, real, yet showed her something utterly impossible.\n",
      "\n",
      "Her mother smiled, a gentle, knowing curve of her lips. She watched Lily's face, alight with a wonder she herself had felt as a child, and felt a familiar warmth spread through her. \"Because, my sweet star-gazer,\" she said softly, tracing the imagined constellations Lily pointed out on the window, \"the sky is very big. The sun is so bright, it lights up our little piece of it, making it blue and hiding the other lights. But beyond it, even when our sun is shining, the stars have always been there, waiting patiently for us to look.\"\n",
      "\n",
      "Lily looked from the eyepiece to the window again, her eyes wide. The blue seemed less like an ending and more like a curtain. The stars, no longer just distant lights, felt like secrets held just beyond reach. A universe of wonder, now with a hint of understanding, opened before her very eyes. She nodded, the abstract idea finally beginning to click into place.\n",
      "CriticAgent > APPROVED\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"Write a short story about a little girl who sees stars and blue sky at the same time\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorlake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
